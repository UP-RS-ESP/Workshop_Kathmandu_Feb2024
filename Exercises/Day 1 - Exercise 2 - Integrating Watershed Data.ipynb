{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ceb959e",
   "metadata": {},
   "source": [
    "# Exercise 2 - Google Earth Engine for Watershed Data\n",
    "\n",
    "In this exercise, we will use Google Earth Engine to access long time series of satellite data over extensive areas. This is a nice way to do simple analysis over large areas -- for example, what is the average winter temperature over a watershed? \n",
    "\n",
    "\n",
    "## Choosing A Data Source\n",
    "\n",
    "There are many climate data sets available on Earth Engine, some of which we have seen in the previous exercise. One nice data set that covers many environmental variables is ERA5: [https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5)\n",
    "\n",
    "ERA5 data provides well-calibrated model outputs from 1940 until the present day -- many of them at hourly resolution! This is a globally consistent data set that is often used to look at temperature, rainfall, and other environmental trends. It also is used to make projections about long-term changes in the environment due to climate change.\n",
    "\n",
    "There are two main goals for this exercise:\n",
    "\n",
    "1. Generate time series of environmental parameters (e.g., rainfall sum over a watershed)\n",
    "2. Generate maps of long-term averages and trends (e.g., average summer temperature over a watershed)\n",
    "\n",
    "Both of these goals can be accomplished using the same ERA5 data -- we will just be focusing either on a time dimension or the spatial dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dcf7c3",
   "metadata": {},
   "source": [
    "To start off, we will load in our required modules again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46367a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime, json\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe304197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "print(ee.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4aee1",
   "metadata": {},
   "source": [
    "Let's test again that everything is working as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = ee.Image('USGS/SRTMGL1_003') #Load in the global SRTM elevation data set\n",
    "xy = ee.Geometry.Point([86.9250, 27.9881]) #Define the location of interest\n",
    "elev = dem.sample(xy, 30).first().get('elevation').getInfo() #Sample the data set at that point\n",
    "print('Mount Everest elevation (m):', elev) #Print the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24523b7",
   "metadata": {},
   "source": [
    "## Choosing a Study Area\n",
    "\n",
    "Let's load in a watershed outline. I have chosen an outline that roughly corresponds to the Trishuli. I can open it on [geojson.io](geojson.io): \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tasmi/Workshop_Kathmandu_Feb2024/main/Exercises/Images/Trishuli.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "You can find the file for download [here](https://raw.githubusercontent.com/tasmi/Workshop_Kathmandu_Feb2024/main/GeoData/Trishuli.geojson). You can also copy and paste that raw data into [geojson.io](geojson.io) to visualize this on a map as above.\n",
    "\n",
    "You are also welcome to use any geographic data set you like (shapefile, etc) if you already have a watershed outline for your study area. \n",
    "\n",
    "We can load that data in with Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29db6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trishuli_outline = gpd.read_file('GeoData/Trishuli.geojson')\n",
    "print(trishuli_outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fad569",
   "metadata": {},
   "source": [
    "Now we can turn that data into an Earth Engine geometry that we can use for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = ee.Geometry.MultiPolygon(ee.List(mapping(trishuli_outline.geometry[0])['coordinates']))\n",
    "print(area_of_interest.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de170ad",
   "metadata": {},
   "source": [
    "## Loading in ERA5 Data\n",
    "\n",
    "Data from ERA5 is available in several formats on Earth Engine. For example:\n",
    "\n",
    "1. ERA5 Daily: [https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_DAILY](https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_DAILY)\n",
    "2. ERA5 Monthy: [https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_MONTHLY](https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_MONTHLY)\n",
    "3. ERA5 Hourly: [https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_HOURLY](https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_HOURLY)\n",
    "\n",
    "Daily and Monthly data go from 1979-Present (minus 3 months), Hourly data starts at 1950. \n",
    "\n",
    "Let's open up the different data sets and compare their sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ad415",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\")\n",
    "daily =  ee.ImageCollection(\"ECMWF/ERA5/DAILY\")\n",
    "monthly =  ee.ImageCollection(\"ECMWF/ERA5/MONTHLY\")\n",
    "hour_length = hourly.size().getInfo()\n",
    "daily_length = daily.size().getInfo()\n",
    "monthly_length = monthly.size().getInfo()\n",
    "print('Hourly', hour_length)\n",
    "print('Daily', daily_length)\n",
    "print('Monthly', monthly_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b926962",
   "metadata": {},
   "source": [
    "That is a lot of data! To make things run more quickly, we will focus today on the **monthly** data set. However, if you are interested in using the higher-resolution data, it is easy to simply switch your data source and re-run the same analysis!\n",
    "\n",
    "## Calculating an Average Time Series\n",
    "\n",
    "The first goal is to perform a similar analysis as to what we did this morning, except now we will focus over a larger area. Instead of only getting one value from each time (day or month), we will get the average (or minimum, maximum, etc) of all values that are within our watershed.\n",
    "\n",
    "Thankfully, the calculations are quite similar to what we have done earlier -- it does not take very much more effort to process much more data!\n",
    "\n",
    "First, let's look at what different data sets we can use: [https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_MONTHLY](https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_MONTHLY)\n",
    "\n",
    "I am going to start with **total_precipitation**, but feel free to choose a different variable. The steps will be exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eabb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_time_series_data(collection, geometry, variable):\n",
    "    def create_time_series(image):\n",
    "        date = image.get('system:time_start')\n",
    "        mean = image.reduceRegion(reducer=ee.Reducer.mean(), geometry=geometry).get(variable)\n",
    "        maximum = image.reduceRegion(reducer=ee.Reducer.max(), geometry=geometry).get(variable)\n",
    "        minimum = image.reduceRegion(reducer=ee.Reducer.min(), geometry=geometry).get(variable)\n",
    "        ft = ee.Feature(None, {'date': ee.Date(date).format('Y/M/d'), 'min': minimum, 'mean':mean, 'max':maximum})\n",
    "        return ft\n",
    "\n",
    "    time_series = collection.map(create_time_series).getInfo()\n",
    "    \n",
    "    dates, means, mins, maxs = [], [], [], []\n",
    "    for f in time_series['features']:\n",
    "        properties = f['properties']\n",
    "        date = properties['date']\n",
    "        dates.append(datetime.datetime.strptime(date,'%Y/%m/%d')) #Convert the date into something that Python recognizes\n",
    "        val = properties['mean']\n",
    "        means.append(val)\n",
    "        val = properties['min']\n",
    "        mins.append(val)\n",
    "        val = properties['max']\n",
    "        maxs.append(val)\n",
    "        \n",
    "    return np.array(dates), np.array(means), np.array(mins), np.array(maxs)\n",
    "\n",
    "dates, means, mins, maxs = export_time_series_data(monthly, area_of_interest, 'total_precipitation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f47142",
   "metadata": {},
   "source": [
    "Notice that we use several different _reducers_ -- these are basic math functions that are available on Google Earth Engine. They allow us to perform complex operations using a simple line of code. There are quite a few available, see here: [https://developers.google.com/earth-engine/guides/reducers_intro](https://developers.google.com/earth-engine/guides/reducers_intro)\n",
    "\n",
    "Now that we have the data, we can plot the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f657bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax, ax2, ax3) = plt.subplots(3, figsize=(10,10))\n",
    "\n",
    "ax.plot(dates, mins, 'b')\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Minimum Monthly Precipitation Sum (m)')\n",
    "\n",
    "ax2.plot(dates, means, 'g')\n",
    "ax.set_ylim(ymin=0)\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Mean Monthly Precipitation Sum (m)')\n",
    "\n",
    "ax3.plot(dates, maxs, 'r')\n",
    "ax3.set_ylim(ymin=0)\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_ylabel('Max Monthly Precipitation Sum (m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6f436",
   "metadata": {},
   "source": [
    "This is very similar to what we did in the first exercise, except that we are looking at **a much larger area**. This also took very little time, but provided us a _watershed average_ precipitation data set over a long time period. This is very useful for looking at historical trends, abnormal years, and changes in seasonality of precipitation (or other variables). \n",
    "\n",
    "Let's make one more plot that shows how varied precipitation can be within one watershed -- if I simply subtract the minimum from the maximum, I can tell how consistent the monthly rainfall sums are across the watershed. This gives me an idea whether all parts of the watershed will receive similar rainfall, and how widely it can vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ac2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "\n",
    "ax.plot(dates, maxs - mins, 'b')\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Range Monthly Precipitation Sum (m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d032bab",
   "metadata": {},
   "source": [
    "That is a really big range! Sometimes there is a difference of more than a meter of precipitation _within the same watershed_. \n",
    "\n",
    "While this is useful information for some purposes, it is also really helpful to display this data on a **map**. To do this, we want to create averages (or minimums, or trends) for each point on our map. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67602f4a",
   "metadata": {},
   "source": [
    "## Creating Long-Term Average Maps\n",
    "\n",
    "We can use the same **reducer** tools to do operations over _space_ instead of _time_. However, since the data we create are much larger, it is not possible to download them directly -- we can only make simple web-based visualizations. However, we can also export the output of our analysis to Google Drive, where we can use it for further analysis.\n",
    "\n",
    "Let's first create a simple long-term monthly mean precipitation sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_mean = monthly.select('total_precipitation').reduce(ee.Reducer.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8cc958",
   "metadata": {},
   "source": [
    "Yes, that is really the whole command! Since we are not doing any of the processing on our computer, Google Earth Engine takes care of most of the heavy work for us. However, it is not possible to directly download the data like the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8899da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lt_mean.getInfo()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f0936",
   "metadata": {},
   "source": [
    "That only gives us _metadata_ about the calculation we have performed. If we want to visualize the data, we can use the _geemap_ Python module.\n",
    "\n",
    "NOTE: You may need to enable the ipyleaflet extension if the below code does not run:\n",
    "\n",
    "    jupyter nbextension enable --py --sys-prefix ipyleaflet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "cenx, ceny = trishuli_outline.centroid[0].x, trishuli_outline.centroid[0].y\n",
    "Map = geemap.Map(center=[ceny, cenx], zoom=6)\n",
    "image_viz_params = {'palette': ['00204C', '213D6B', '555B6C', '7B7A77', 'A59C74', 'D3C064', 'FFE945'],'min': 0,'max': 1, 'opacity':0.9}\n",
    "Map.addLayer(lt_mean, image_viz_params)\n",
    "Map.addLayer(area_of_interest)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08aaa33",
   "metadata": {},
   "source": [
    "This is a nice interactive web map that you can move around in -- you can also click on any point to get a value, change the colors, etc. This can also be exported and added to a website!\n",
    "\n",
    "Let's try this with the maximum monthly precipitation as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a615ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_max = monthly.select('total_precipitation').reduce(ee.Reducer.max())\n",
    "Map = geemap.Map(center=[ceny, cenx], zoom=6)\n",
    "image_viz_params = {'palette': ['00204C', '213D6B', '555B6C', '7B7A77', 'A59C74', 'D3C064', 'FFE945'],'min': 0,'max': 1, 'opacity':0.9}\n",
    "Map.addLayer(lt_max, image_viz_params)\n",
    "Map.addLayer(area_of_interest)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2c3ec",
   "metadata": {},
   "source": [
    "It's quite clear to see the pattern of the monsoon in the data -- even if it isn't the highest spatial resolution! \n",
    "\n",
    "Let's try one more reducer: linear trend. We need to do one extra step before we use this reducer, which is to add a _time_ band (so we have an x and a y for our linear trend). We can do this with a simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mm(image):\n",
    "    mm_band = image.select('total_precipitation').multiply(1000).set('system:time_start', image.get('system:time_start'))\n",
    "    return image.addBands(mm_band.rename('total_precipitation_mm'))\n",
    "\n",
    "def time_regression(collection, variable, spacing='year'):\n",
    "    def addtime(image):\n",
    "        date = image.date()\n",
    "        years = date.difference(ee.Date('1900-01-01'), spacing)\n",
    "        return image.addBands(ee.Image(years).rename('t')).float()\n",
    "\n",
    "    prepped = collection.map(addtime) #Add the new time band\n",
    "    to_process = prepped.select(['t', variable]) #Choose what variable to regress against time\n",
    "    \n",
    "    return to_process.reduce(ee.Reducer.linearFit())\n",
    "\n",
    "monthly_mm = monthly.map(to_mm)\n",
    "precip_annual_trend = time_regression(monthly_mm, 'total_precipitation_mm').select('scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=[ceny, cenx], zoom=6)\n",
    "image_viz_params = {'palette': ['3B4CC0', '6F91F2', 'A9C5FC', 'DDDDDD', 'F6B69B', 'E6745B', 'B40426'],'min': -1,'max': 1, 'opacity':0.9}\n",
    "Map.addLayer(precip_annual_trend, image_viz_params)\n",
    "Map.addLayer(area_of_interest)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b193746",
   "metadata": {},
   "source": [
    "We can run the same analysis using _air temperature_ to compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71707a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_annual_trend = time_regression(monthly, 'mean_2m_air_temperature').select('scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb987da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=[ceny, cenx], zoom=6)\n",
    "image_viz_params = {'palette': ['3B4CC0', '6F91F2', 'A9C5FC', 'DDDDDD', 'F6B69B', 'E6745B', 'B40426'],'min': -0.05,'max': 0.05, 'opacity':0.9}\n",
    "Map.addLayer(temp_annual_trend, image_viz_params)\n",
    "Map.addLayer(area_of_interest)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b048eb",
   "metadata": {},
   "source": [
    "This goes really quick! This is a very nice way to quickly analyze large climate data without having to download anything.\n",
    "\n",
    "If you want to use these images for further analysis or for making your own maps, we can _export_ the data to Google Drive. This can be done with this small function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_export(image, crs, filename, scale, region, maxPixels=1e12, cloud_optimized=True):\n",
    "    task_config = {'fileNamePrefix': filename,'crs': crs,'scale': scale,'maxPixels': maxPixels, 'fileFormat': 'GeoTIFF', 'formatOptions': {'cloudOptimized': cloud_optimized}, 'region': region,}\n",
    "    task = ee.batch.Export.image.toDrive(image, filename, **task_config)\n",
    "    task.start()\n",
    "    \n",
    "run_export(temp_annual_trend, 'epsg:4326', 'ERA5_MonthlyMeanTemp_Trend_1979-2023', scale=27830, region=area_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2037c9",
   "metadata": {},
   "source": [
    "Let's also export one over a bigger area for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c12aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "minx, maxx, miny, maxy = [65, 110, 25, 45]\n",
    "regional_extent = ee.Geometry.Polygon([[minx, maxy], [maxx, maxy], [maxx, miny], [minx, miny]])\n",
    "run_export(temp_annual_trend, 'epsg:4326', 'ERA5_MonthlyMeanTemp_Trend_1979-2023_large', scale=27830, region=regional_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c832998",
   "metadata": {},
   "source": [
    "This runs quite quickly: \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tasmi/Workshop_Kathmandu_Feb2024/main/Exercises/Images/EE_Tasks.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "You can see the progress at [https://code.earthengine.google.com/tasks](https://code.earthengine.google.com/tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74b925",
   "metadata": {},
   "source": [
    "We can also now open up the data in QGIS to visualize further:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tasmi/Workshop_Kathmandu_Feb2024/main/Exercises/Images/QGIS_Output.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Notice that the size of the data is very small -- if we wanted to download the whole original data set, that would be many of hundreds of GB. Instead, we can perform some simple analysis on the data and only export the results. This is one of the most important parts of Google Earth Engine -- we now have access to a huge library of data, as well as the tools to do powerful analysis without needing our own big computer setup. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5c188",
   "metadata": {},
   "source": [
    "## Bonus Example -- More Complex Analysis\n",
    "\n",
    "Let's do one more quick exercise which focuses on higher-resolution data. I want to make two maps focusing on the distribution of snow within my watershed. These should cover two topics:\n",
    "\n",
    "1. Number of Snow Cover Days (on average)\n",
    "2. Average Winter (December-January-February) Snow Cover Percentage\n",
    "\n",
    "To do this, I will use MODIS Snow Cover Data (500 m resolution), available here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4105b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winter_filter(collection):\n",
    "    allfilts = []\n",
    "    for m in [12, 1, 2]:\n",
    "        allfilts.append(ee.Filter.calendarRange(m, m, 'month'))\n",
    "    \n",
    "    filt = ee.Filter.Or(allfilts)    \n",
    "    return collection.filter(filt)\n",
    "\n",
    "snow_cover = ee.ImageCollection(\"MODIS/061/MOD10A1\").select('NDSI_Snow_Cover')\n",
    "djf_snow_cover = winter_filter(snow_cover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b139bdb",
   "metadata": {},
   "source": [
    "First let's get the average winter snow cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b51f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_snow_cover = djf_snow_cover.reduce(ee.Reducer.mean())\n",
    "\n",
    "Map = geemap.Map(center=[ceny, cenx], zoom=8)\n",
    "image_viz_params = {'palette': ['3B4CC0', '6F91F2', 'A9C5FC', 'DDDDDD', 'F6B69B', 'E6745B', 'B40426'],'min': 0,'max': 100, 'opacity':0.9}\n",
    "Map.addLayer(avg_snow_cover, image_viz_params)\n",
    "Map.addLayer(area_of_interest)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f49075",
   "metadata": {},
   "source": [
    "Now let's count the number of days that are above 5% snow covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a150bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mask_(image):\n",
    "    mask = image.lt(5)\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "masked_sca = snow_cover.map(mask_)\n",
    "count = masked_sca.reduce(ee.Reducer.count())\n",
    "\n",
    "Map = geemap.Map(center=[ceny, cenx], zoom=8)\n",
    "image_viz_params = {'palette': ['3B4CC0', '6F91F2', 'A9C5FC', 'DDDDDD', 'F6B69B', 'E6745B', 'B40426'],'min': 100,'max': 5000, 'opacity':0.9}\n",
    "Map.addLayer(count, image_viz_params)\n",
    "Map.addLayer(area_of_interest)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1815b99d",
   "metadata": {},
   "source": [
    "We can also export the data as before -- this will take a little longer, but still not very long for how much data is being used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_snow_cover = djf_snow_cover.reduce(ee.Reducer.mean())\n",
    "run_export(avg_snow_cover, 'epsg:4326', 'MODIS_WinterSnowCover_2000-2023', scale=500, region=regional_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35751b0a",
   "metadata": {},
   "source": [
    "## Further Information\n",
    "\n",
    "This was a short introduction to show what the possibilities are with online data processing. There are many data sets available on Google Earth Engine, covering many different environmental parameters. A full list can be found here: [https://developers.google.com/earth-engine/datasets](https://developers.google.com/earth-engine/datasets)\n",
    "\n",
    "There are also many community data sets hosted here: [https://gee-community-catalog.org/](https://gee-community-catalog.org/) These include soil data, hydrological data, and climate data. Any of these data sets can be used the same way as we did in this example!\n",
    "\n",
    "There is usually some data set that can be used to answer your question!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
