{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c16a552",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Google Earth Engine and Cloud Computing\n",
    "\n",
    "Google Earth Engine is an online tool which provides access to vast amounts of geospatial data, as well as infrastructure for working with that data. This means that Google hosts all of the large data sets without you having to download them. It also means that the expensive processing happens on their computers, and that you can do complex analysis on a small computer and without lots of internet bandwidth. \n",
    "\n",
    "For a list of available data sets on Google Earth Engine, you can visit this link: [https://developers.google.com/earth-engine/datasets](https://developers.google.com/earth-engine/datasets)\n",
    "\n",
    "For a further introduction to Google Earth Engine, please see this link: [https://earthengine.google.com/](https://earthengine.google.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abb435",
   "metadata": {},
   "source": [
    "In this exercise, we will use Google Earth Engine to access a long time series of satellite data for point locations. This is useful if you want to know how rainfall or temperature has changed in a specific location over a long point in time based on satellite data. \n",
    "\n",
    "To do this, we will use the Python computer language, which we can link to Google Earth Engine. There are detailed instructions on how to set this up [here](https://developers.google.com/earth-engine/python_install).\n",
    "\n",
    "As an alternative, you can run all of the same analysis in [Google Colab](https://colab.research.google.com/). To do so, download this [file](https://github.com/tasmi/Workshop_Kathmandu_Feb2024/blob/main/Exercises/Day%201%20-%20Exercise%201%20-%20Climate%20Data%20for%20Specific%20Locations.ipynb) to your Google Colab instance. You can then follow the exercise in the same way as if you ran it on your own computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4c2d8",
   "metadata": {},
   "source": [
    "## Importing Python Modules\n",
    "\n",
    "The first step to running any Python program is to import _modules_, which are small sets of commands that do specific tasks. In this exercise, we want to use three modules: \n",
    "\n",
    "1. [Google Earth Engine](https://github.com/google/earthengine-api)\n",
    "2. [Matplotlib](https://matplotlib.org/)\n",
    "3. [Numpy](https://numpy.org/)\n",
    "\n",
    "These will provide us access to Google's servers, utilities for plotting data, and utilities for doing mathematical operations. \n",
    "\n",
    "To add modules to your Python program, use the _import_ line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7622732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "#The first time you use the earthengine module, you need to link your account credentials. Afterwards, your\n",
    "#computer stores the authentication file\n",
    "\n",
    "#ee.Authenticate()\n",
    "\n",
    "ee.Initialize()\n",
    "print(ee.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ccdae8",
   "metadata": {},
   "source": [
    "Now that we have access to those Python modules, we can test if they are working and we can access Google's servers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0650ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = ee.Image('USGS/SRTMGL1_003') #Load in the global SRTM elevation data set\n",
    "xy = ee.Geometry.Point([86.9250, 27.9881]) #Define the location of interest\n",
    "elev = dem.sample(xy, 30).first().get('elevation').getInfo() #Sample the data set at that point\n",
    "print('Mount Everest elevation (m):', elev) #Print the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1d07b",
   "metadata": {},
   "source": [
    "Those four lines of code do a few steps:\n",
    "\n",
    "1. Import the global SRTM Elevation data set at 30 m (see details [here](https://developers.google.com/earth-engine/datasets/catalog/USGS_SRTMGL1_003))\n",
    "2. Choose a point location based on latitude and longitude, which is defined as a 'Point Geometry'\n",
    "3. Sample the elevation data at 30 m resolution, and use _.getInfo()_ to download the result\n",
    "4. Print the result\n",
    "\n",
    "The important thing here is that no processing is done on your computer, and data is only downloaded when you use _.getInfo()_. This means you can do complex operations without having to download anyting but the final answer. We don't need to download the elevation data itself, we only want the elevation at a single point! Google Earth Engine takes care of the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac0b29",
   "metadata": {},
   "source": [
    "## Defining a Location of Interest\n",
    "\n",
    "The main goal of this exercise is to choose a location of interest (for example, a glacier, a hydropower project, a weather station location, etc) and extract a time series of satellite measurements. The main benefit here is that we can skip the step of figuring out how to download, process, and sample very large data sets, and only concentrate on receiving the data we actually are interested in. In the second exercise today we will look at getting data over a larger area, but for now we will focus only on single point locations.\n",
    "\n",
    "The easiest way to define a point location is with _latitude and longitude_, which you may already have from GPS measurements or known data about a climate station. Two easy alternative ways to get GPS coordinates is by using Google Maps or the website [geojson.io](https://geojson.io/). \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tasmi/Workshop_Kathmandu_Feb2024/main/Images/HotelKutumba.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "For example, if I right-click on the Google Maps location of our workshop location, I get a _latitude, longitude_ pair. This is the (Y, X) location we are on the globe!\n",
    "\n",
    "We can use that directly to make a Google Earth Engine geometry, which we can then use to extract data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486996ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE THAT THIS IS [X, Y], and is opposite of the output from Google Maps!\n",
    "hotel = ee.Geometry.Point([85.31634, 27.6825]) \n",
    "elev = dem.sample(hotel, 30).first().get('elevation').getInfo() #Sample the data set at that point\n",
    "print('Hotel Kutumba elevation (m):', elev) #Print the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85a82b",
   "metadata": {},
   "source": [
    "## Choosing Data \n",
    "\n",
    "There is a **massive** number of data sets we can choose from on Google Earth Engine. If we look at the [data catalog](https://developers.google.com/earth-engine/datasets), we can search for 'Climate' data as a first step:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tasmi/Workshop_Kathmandu_Feb2024/main/Images/ClimateData.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "Let's choose a simple rainfall data set: [CHIRPS Daily Precipitation](https://developers.google.com/earth-engine/datasets/catalog/UCSB-CHG_CHIRPS_DAILY)\n",
    "\n",
    "This data covers the whole globe for the past 30+ years, and gives us daily total precipitation. We can add it to our Python script with the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b871db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\")\n",
    "data_length = rainfall.size().getInfo()\n",
    "print(data_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9199b5",
   "metadata": {},
   "source": [
    "This means we have more than 15000 days of precipitation data that we can access through that one line of Python code! That is a lot of data.\n",
    "\n",
    "We can select a smaller subset, for example the last year by using a _filter_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\").filterDate('2023-01-01', '2024-03-01') \n",
    "data_length = rainfall.size().getInfo()\n",
    "print(data_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341f488",
   "metadata": {},
   "source": [
    "This is much shorter -- and will be easier to make a quick plot with. We can download the data using _sample_, as we did with elevation. However, this time we want to get **all of the values**, one for each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series(image):\n",
    "    date = image.get('system:time_start')\n",
    "    value = image.reduceRegion(reducer=ee.Reducer.mean(), geometry=hotel).get('precipitation')\n",
    "    ft = ee.Feature(None, {'date': ee.Date(date).format('Y/M/d'), 'rainfall': value})\n",
    "    return ft\n",
    "\n",
    "time_series = rainfall.map(create_time_series).getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b9694",
   "metadata": {},
   "source": [
    "This gives us a long list of _dates_ and _values_ by going through each individual rainfall grid and sampling only at our 'hotel' location. However, it is not in a very nice data format -- we need to convert it into something a little nicer to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ef3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160cbf5",
   "metadata": {},
   "source": [
    "We can go through each item in the long list of data and extract only the pieces we are interested in -- the date and the amount of rainfall. We do this via a [for loop](https://www.w3schools.com/python/python_for_loops.asp). We can then print each value we extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9cd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in time_series['features']:\n",
    "    properties = f['properties']\n",
    "    date = properties['date']\n",
    "    rain = properties['rainfall']\n",
    "    print(date, rain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ea4c2",
   "metadata": {},
   "source": [
    "We can also store each of these values in a list, so we can use them to make a simple plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb3b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates, rainfalls = [], []\n",
    "for f in time_series['features']:\n",
    "    properties = f['properties']\n",
    "    date = properties['date']\n",
    "    rain = properties['rainfall']\n",
    "    dates.append(datetime.datetime.strptime(date,'%Y/%m/%d')) #Convert the date into something that Python recognizes\n",
    "    rainfalls.append(rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dates, rainfalls)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Daily Precipitation (mm/day)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30cb4f",
   "metadata": {},
   "source": [
    "Let's compare that to the same time series from [http://www.mfd.gov.np/city?id=31](http://www.mfd.gov.np/city?id=31):\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tasmi/Workshop_Kathmandu_Feb2024/main/Images/Rainfall_2023.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "\n",
    "We can add a vertical line marking the maximum rainfall day to make comparison easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77929b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_rainfall = np.array(rainfalls).max()\n",
    "print(maximum_rainfall)\n",
    "maximum_date = np.array(dates)[np.array(rainfalls) == maximum_rainfall]\n",
    "print(maximum_date)\n",
    "\n",
    "plt.plot(dates, rainfalls)\n",
    "plt.ylim(ymin=0)\n",
    "plt.axvline(maximum_date, 0, maximum_rainfall, color='r', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Daily Precipitation (mm/day)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef773baf",
   "metadata": {},
   "source": [
    "We can also look specically at the value for the largest rainfall day in the MFD data set (July 17):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c39e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_17_rainfall = np.array(rainfalls)[np.array(dates) == datetime.datetime(2023, 7, 17, 0, 0)]\n",
    "print(july_17_rainfall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1196ff1",
   "metadata": {},
   "source": [
    "That is almost exactly the same as the MFD data! This is a nice confirmation that our data is useful. \n",
    "\n",
    "The main reason the data will differ is that the MFD data is for a single _point_, and the rainfall data from Google Earth Engine is a _grid_ which covers a relatively larger area (5 x 5 km). This means that the Earth Engine data integrates over a larger area, and doesn't always match perfectly with the single point station data. \n",
    "\n",
    "However, **not all locations have station data, and it is not always easy to get the data that does exist!** This means that we can instead use satellite data for some analyses -- especially in remote areas that are hard to reach and install monitoring stations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d07659",
   "metadata": {},
   "source": [
    "## Looking at Multiple Types of Data\n",
    "\n",
    "Let's choose another more remote location and acquire different types of data. For example, we can get rainfall, vegetation health, and snow-cover data all at once to compare their relationship.\n",
    "\n",
    "I am going to use a point location near Langtang. Here is where I am choosing: \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tasmi/Workshop_Kathmandu_Feb2024/main/Images/Langtang.png\" alt=\"\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langtang = ee.Geometry.Point([85.51593, 28.21618]) \n",
    "elev = dem.sample(langtang, 30).first().get('elevation').getInfo() #Sample the data set at that point\n",
    "print('Langtang elevation (m):', elev) #Print the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af75fa6",
   "metadata": {},
   "source": [
    "Let's add the same rainfall data, as well as [temperature](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD11A1) and [snow-cover](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD10A1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4540374",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\").filterDate('2022-01-01', '2024-03-01') #Last two years\n",
    "temperature = ee.ImageCollection(\"MODIS/061/MOD11A1\").select('LST_Day_1km').filterDate('2022-01-01', '2024-03-01') #Last two years\n",
    "veg_cover = ee.ImageCollection(\"MODIS/061/MOD13A2\").select('NDVI').filterDate('2022-01-01', '2024-03-01') #Last two years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652cbd18",
   "metadata": {},
   "source": [
    "We can expand our 'create_time_series' function from above to sample different data for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series(data, variable, name):\n",
    "    def create_(image):\n",
    "        date = image.get('system:time_start')\n",
    "        value = image.reduceRegion(reducer=ee.Reducer.mean(), geometry=hotel).get(variable)\n",
    "        ft = ee.Feature(None, {'date': ee.Date(date).format('Y/M/d'), name: value})\n",
    "        return ft\n",
    "    return data.map(create_).getInfo() \n",
    "\n",
    "rain_series = create_time_series(rainfall, 'precipitation', 'rainfall')\n",
    "temp_series = create_time_series(temperature, 'LST_Day_1km', 'temperature')\n",
    "veg_series = create_time_series(veg_cover, 'NDVI', 'veg_cover')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4397996f",
   "metadata": {},
   "source": [
    "Now convert it into something easier to plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04aff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(time_series, name):\n",
    "    dates, datas = [], []\n",
    "    for f in time_series['features']:\n",
    "        properties = f['properties']\n",
    "        date = properties['date']\n",
    "        try:\n",
    "            data = properties[name]\n",
    "            datas.append(data)\n",
    "            dates.append(datetime.datetime.strptime(date,'%Y/%m/%d')) #Convert the date into something that Python recognizes\n",
    "        except:\n",
    "            pass\n",
    "    return np.array(dates), np.array(datas)\n",
    "\n",
    "rdates, rain = create_data(rain_series, 'rainfall')\n",
    "tdates, temp = create_data(temp_series, 'temperature')\n",
    "vdates, veg = create_data(veg_series, 'veg_cover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a305fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax, ax2, ax3) = plt.subplots(3, figsize=(10,10))\n",
    "\n",
    "ax.plot(rdates, rain, 'b')\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Daily Precipitation (mm/day)')\n",
    "\n",
    "#Note -- We need to convert temperature to celcius!\n",
    "temp_c = temp*0.02 - 273.15\n",
    "ax2.plot(tdates, temp_c, 'r')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Daily Temperature (C)')\n",
    "\n",
    "#Note -- We need to rescale the NDVI data \n",
    "ax3.plot(vdates, veg *  0.0001, 'g')\n",
    "ax3.set_ylim(0, 0.5)\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_ylabel('Daily Vegetation Greenness')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d8577",
   "metadata": {},
   "source": [
    "## Further Information\n",
    "\n",
    "This is a very simple way to pull data from satellites for specific locations. There are many data sets available on Google Earth Engine, covering many different environmental parameters. A full list can be found here: [https://developers.google.com/earth-engine/datasets](https://developers.google.com/earth-engine/datasets)\n",
    "\n",
    "There are also many community data sets hosted here: [https://gee-community-catalog.org/](https://gee-community-catalog.org/) These include soil data, hydrological data, and climate data. Any of these data sets can be used the same way as we did in this example!\n",
    "\n",
    "After the break, we will explore how to get larger data, for example covering an entire watershed, and how to make simple maps directly from that data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d1cf5",
   "metadata": {},
   "source": [
    "### Bonus: Downloading the Data to CSV\n",
    "\n",
    "If you want to save the climate and environmental data that you create (for example, to open in Excel, or add to another data set), you can use Python as well. Since we already have the data downloaded as a list of dates and values, we can quickly write thme to a .csv file. The easiest way to do this is with [_pandas_](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e86bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'date':rdates, 'rainfall':rain})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf31bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot('date', 'rainfall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd3927",
   "metadata": {},
   "source": [
    "This is a very easy way to work with time series data -- we will go more into this in the next exercises. For now, however, we can export our data with a simple command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Time Series/Kathmandu_Rainfall.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
