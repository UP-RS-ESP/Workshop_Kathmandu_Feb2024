{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025d58d1",
   "metadata": {},
   "source": [
    "# Exercise 1 - Working with High-Frequency Data\n",
    "\n",
    "So far we have worked with satellite data, which is often recorded at the timescale of days, weeks, or months. This is very different from the frequency of the data that we can get from on-the-ground sensors. Depending on your needs, you can have data recorded at the scale of hours, minutes, seconds, or even higher!\n",
    "\n",
    "The goal of this exercise is to look at the capabilities of higher frequency data -- much beyond the typical daily or weekly data sets from satellites or larger weather station networks. \n",
    "\n",
    "In this first exercise, we are going to look at both higher-frequency satellite data and the outputs of some sensor data installed in the Trishuli to try to understand the usefulness and difficulties associated with high-frequency data. \n",
    "\n",
    "We can start by importing some Python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31747516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import datetime, json\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "print(ee.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3727b64",
   "metadata": {},
   "source": [
    "## High-Frequency Satellite Data\n",
    "\n",
    "Let's return to the 3-hourly GPM data we worked with yesterday: [https://developers.google.com/earth-engine/datasets/catalog/NASA_GPM_L3_IMERG_V06](https://developers.google.com/earth-engine/datasets/catalog/NASA_GPM_L3_IMERG_V06)\n",
    "\n",
    "This is one of the best high-frequency climate records from satellites -- there are not many sensors that give us data more often than once a day. In fact, most sensors only give data every 2-3 weeks! This means they are really good for looking at long-term trends, but very bad for finding short-term changes and any rapid events.\n",
    "\n",
    "Google Earth Engine sets a limit to how many data points you can access directly -- something around 5000 is the maximum. If we want to look at a longer time series -- for example, the last 5 years -- we need to export the data to our Google Drive like we did with the gridded data.\n",
    "\n",
    "Let's create a high-frequency time series for the Trishuli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trishuli_outline = gpd.read_file('GeoData/Trishuli.geojson')\n",
    "area_of_interest = ee.Geometry.MultiPolygon(ee.List(mapping(trishuli_outline.geometry[0])['coordinates']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51682da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_timeseries_todrive(collection, filename, scale, region, agg_fx=ee.Reducer.median()):\n",
    "    def createTS(image):\n",
    "        date = image.get('system:time_start')\n",
    "        value = image.reduceRegion(agg_fx, region, scale)\n",
    "        ft = ee.Feature(None, {'system:time_start': date, 'date': ee.Date(date).format('Y/M/d-H:m:s'), 'val': value})\n",
    "        return ft\n",
    "    \n",
    "    TS = collection.filterBounds(region).map(createTS)\n",
    "    \n",
    "    task_config = {'description': filename, 'fileFormat': 'CSV'}\n",
    "    task = ee.batch.Export.table.toDrive(TS, **task_config)\n",
    "    task.start()\n",
    "\n",
    "def mask_(image):\n",
    "    mask = image.gt(0.5)\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "hr_rainfall = ee.ImageCollection(\"NASA/GPM_L3/IMERG_V06\").select('precipitationCal').filterDate('2019-01-01', '2024-01-01')\n",
    "hr_rainfall = hr_rainfall.map(mask_) #Remove low values\n",
    "export_timeseries_todrive(hr_rainfall, 'Trishuli_GPM_Med', scale=11132, region=area_of_interest)\n",
    "export_timeseries_todrive(hr_rainfall, 'Trishuli_GPM_Sum', scale=11132, region=area_of_interest, agg_fx=ee.Reducer.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5dfe4b",
   "metadata": {},
   "source": [
    "For me this took about 45 minutes to run. You can find the files directly on Github as well: [link](). \n",
    "\n",
    "We can now open this file with _pandas_ and have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370847b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Time Series/Trishuli_GPM_Med.csv') #Load in our CSV File\n",
    "dates = [pd.Timestamp(x) for x in df.date] #Fix the date to something Python recognizes\n",
    "rain = [float(x.split('=')[1].replace('}','').replace('null','0')) for x in df.val] #Fix the value to something Python recognizes\n",
    "\n",
    "s = pd.Series(rain, index=dates) #Turn this into an easy to work with time series\n",
    "rs_d = s.resample('D').mean() #Get the daily mean\n",
    "rs_m = s.resample('M').mean() #Get the monthly mean\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(14,6))\n",
    "ax.plot(s.index, s.values, 'rx', markersize=2, label='Hourly Data')\n",
    "ax.plot(rs_d.index, rs_d.values, 'b.', label='Daily Mean')\n",
    "ax.plot(rs_m.index, rs_m.values, 'co', label='Monthly Mean')\n",
    "ax.set_xlabel('Time', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Precipitation Rate (mm/hr)', fontsize=16, fontweight='bold')\n",
    "ax.set_title('Trishuli GPM Precipitation, 2019-2023', fontsize=18, fontweight='bold')\n",
    "ax.set_ylim(0,30)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76873ad",
   "metadata": {},
   "source": [
    "We can do the same thing with daily precipitation sums instead of averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Time Series/Trishuli_GPM_Sum.csv') #Load in our CSV File\n",
    "dates = [pd.Timestamp(x) for x in df.date] #Fix the date to something Python recognizes\n",
    "rain = [float(x.split('=')[1].replace('}','').replace('null','0')) for x in df.val] #Fix the value to something Python recognizes\n",
    "\n",
    "s = pd.Series(rain, index=dates) #Turn this into an easy to work with time series\n",
    "rs_d = s.resample('D').mean() #Get the daily mean\n",
    "rs_m = s.resample('M').mean() #Get the monthly mean\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(14,6))\n",
    "ax.plot(s.index, s.values, 'rx', markersize=1, label='Hourly Data')\n",
    "ax.plot(rs_d.index, rs_d.values, 'b.', label='Daily Mean')\n",
    "ax.plot(rs_m.index, rs_m.values, 'co', label='Monthly Mean')\n",
    "ax.set_xlabel('Time', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Precipitation Sum (mm)', fontsize=16, fontweight='bold')\n",
    "ax.set_title('Trishuli GPM Precipitation, 2019-2023', fontsize=18, fontweight='bold')\n",
    "ax.set_ylim(0,250)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6ccb8",
   "metadata": {},
   "source": [
    "This makes it really clear how much data is lost by only looking at daily or monthly averages (or sums). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92928d9",
   "metadata": {},
   "source": [
    "## Local Monitoring Data\n",
    "\n",
    "With our own sensors, we can collect data at much higher frequencies -- even down to every second! However, we start to have problems with **actually using** that data -- if there is too much data, it becomes very hard to process.\n",
    "\n",
    "For example, for one of our stations in Trishuli, we have more than **18 Million** measurements since May 2023. That is a lot of data! It thus becomes important to decide how much data you actually need, and consider the trade offs between capturing lots of data and having to both transmit that data and work with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ada6f",
   "metadata": {},
   "source": [
    "### Collecting High-Frequency Data\n",
    "\n",
    "In our experience, it is usually best to first collect the _highest possible resolution_ and then choose the best way to make it smaller. Let's take an example of one week of temperature data from one of our sensors. We can start with the highest (1-second) resolution, and work our way down to an optimum for that data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7770e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Time Series/TRDam_Temperature_Feb2024.csv')\n",
    "df['date'] = [pd.Timestamp(x) for x in df.date]\n",
    "s = pd.Series(df.temp.values, index=df.date)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(s.index, s.values, '.', markersize=1)\n",
    "ax.set_title('One-Second Data, n=478,006')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa6870",
   "metadata": {},
   "source": [
    "That is still a LOT of data! Let's try to make the same plot with one minute data, five minute data, and fifteen minute data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e572c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax, ax2, ax3, ax4) = plt.subplots(4, figsize=(12,12))\n",
    "ax.plot(s.index, s.values, 'b.', markersize=1, label='One Second Data')\n",
    "print('1 Second', s.values.shape)\n",
    "\n",
    "rs = s.resample('1min').mean()\n",
    "ax2.plot(rs.index, rs.values, 'rx', label='One Minute Data')\n",
    "print('1 Minute', rs.values.shape)\n",
    "\n",
    "rs = s.resample('5min').mean()\n",
    "ax3.plot(rs.index, rs.values, 'go', label='Five Minute Data')\n",
    "print('5 Minute', rs.values.shape)\n",
    "\n",
    "rs = s.resample('15min').mean()\n",
    "ax4.plot(rs.index, rs.values, 'k^', label='Fifteen Minute Data')\n",
    "print('15 Minute', rs.values.shape)\n",
    "\n",
    "ax.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()\n",
    "ax4.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d938b614",
   "metadata": {},
   "source": [
    "Those graphs all look pretty similar! Unless you really need to know about those really small-scale changes, 5 or 15 minute data is certainly sufficient. It also **substantially** reduces the amount of data you need to work with. We go from 500,000 points to only 600 quite quickly, and without loosing much information. \n",
    "\n",
    "Since we don't expect air temperature to change really rapidly in most cases, 15-minute data would be a good choice to save on data storage space, SIM and WIFI data, and to make it easier to quickly make charts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea73d5",
   "metadata": {},
   "source": [
    "### Transmitting High-Frequency Data\n",
    "\n",
    "Before we continue to doing some processing with our high-frequency data, I wanted to make a quick detour about transmitting data. When you collect your own data, you can choose whether to save the data onto a hard drive or to transmit it over the internet. In some cases, saving the data to a hard drive is the only possibility -- if there is no cell network and you are in a very remote area, sending your data over the internet is not possible. \n",
    "\n",
    "Even when you do have internet, it is not always fast or reliable -- in both cases, it helps to make your data as small as possible to save space and internet bandwidth. One good way to do this is to resample your data to a slower speed, like we have done above to go from 1 second data to 15 minute data. Another important piece is to **compress** your data, for example into a .zip or .rar file. This is also possible to do directly within your data collection script -- you can use the [gzip](https://docs.python.org/3/library/gzip.html) library which is built into Python for this purpose. \n",
    "\n",
    "Once you have compressed your data, we have found that the [rsync](https://linux.die.net/man/1/rsync) tool is a very robust way to transmit data to a web server, an office computer, or directly to your laptop. If you want to find out more about this, please ask us! We would be happy to show how we accomplished this with our monitoring stations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510cced",
   "metadata": {},
   "source": [
    "### Processing High-Frequency Data\n",
    "\n",
    "Once you have received your data, the next question is how to use it best. There are many questions that can only be answered with high-frequency data, such as how quickly conditions change over short time periods, how different day- and night-time data are, and how far extreme temperatures are from the daily average. All of these quantities will change through time, and will give a better understanding of how much change can happen how quickly. \n",
    "\n",
    "Let's first load in our 15-minute data, covering a longer time period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Time Series/TRDam_Temperature_15Min_2023-2024.csv')\n",
    "df['date'] = [pd.Timestamp(x) for x in df.date]\n",
    "s = pd.Series(df['0'].values, index=df.date)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06448f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(s.index, s.values, '.', markersize=1)\n",
    "ax.set_title('15 Minute Data, n=24,787')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e46d8",
   "metadata": {},
   "source": [
    "This is still a LOT of data! However, we can start to see some patterns. Let's zoom in on one month to make this clearer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "jan_2024 = np.logical_and(s.index.year == 2024, s.index.month == 1)\n",
    "jan_data = s[jan_2024]\n",
    "ax.plot(jan_data.index, jan_data.values, '.', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0860e8",
   "metadata": {},
   "source": [
    "Let's try to get three high-frequency metrics:\n",
    "\n",
    "1. Day/night difference\n",
    "2. Difference from daily average\n",
    "3. Rate of temperature change through time\n",
    "\n",
    "Python can understand the dates that we have with our data -- that is how we managed to extract only one month of data. We can also do the same for night, assuming we know what time the sun goes down!\n",
    "\n",
    "We can do a rough estimate by looking only at times near noon and times near midnight to get a rough estimate of our day/night range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "night = np.logical_or(jan_data.index.hour > 21, jan_data.index.hour < 4)\n",
    "day = np.logical_and(jan_data.index.hour > 10, jan_data.index.hour < 16)\n",
    "\n",
    "night_data = jan_data[night]\n",
    "day_data = jan_data[day]\n",
    "\n",
    "#Now resample those to daily data\n",
    "night_rs = night_data.resample('D').min()\n",
    "day_rs = day_data.resample('D').max()\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(day_rs.index, day_rs.values, 'ro')\n",
    "ax.plot(night_rs.index, night_rs.values, 'bx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077eddf4",
   "metadata": {},
   "source": [
    "We can also now calculate the difference between day max/night min for each day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38910d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(day_rs.index, day_rs.values - night_rs.values, 'ko')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585fc7bc",
   "metadata": {},
   "source": [
    "This tells us that our day/night differences are increasing! This is likely do to the start of spring, when things start to warm up more duing the day while still staying cold at night. We can look at the same parameter over the whole time series to see if we're right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b019460",
   "metadata": {},
   "outputs": [],
   "source": [
    "night = np.logical_or(s.index.hour > 21, s.index.hour < 4)\n",
    "day = np.logical_and(s.index.hour > 10, s.index.hour < 16)\n",
    "\n",
    "night_data = s[night]\n",
    "day_data = s[day]\n",
    "\n",
    "#Now resample those to daily data\n",
    "night_rs = night_data.resample('D').min()[:-1]\n",
    "day_rs = day_data.resample('D').max()\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(day_rs.index, day_rs.values - night_rs.values, 'ko')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12727b",
   "metadata": {},
   "source": [
    "As expected, the day/night difference has been increasing since around Novemer. However, it is clear that there is something else going on here -- there are really large changes in the day/night temperature difference throughout the year. This is due to both stronger sunlight during the summer, and the impact of the monsoonal rainfall, which can rapidly change temperatures, especially if rainfall occurs at night. Let's take a closer look at the other two parameters:\n",
    "\n",
    "2. Difference from daily average\n",
    "3. Rate of temperature change through time\n",
    "\n",
    "We can get a daily average and a daily maximum quite easily using the same format we've looked at above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temp = s.resample('D').mean()\n",
    "max_temp = s.resample('D').max()\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(avg_temp.index, max_temp.values - avg_temp.values, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d847563c",
   "metadata": {},
   "source": [
    "Generally there haven't been many real 'high' outliers -- throughout the past year there hasn't been too many times when the 15-minute temperature is particularly high. However, there are a few cold outliers, even in the summer, where the maximum and average daily temperatures are quite similar. \n",
    "\n",
    "We can determine exactly what date that minimum occured on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749976fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_difference = np.argmin(max_temp.values - avg_temp.values)\n",
    "date = max_temp.index[smallest_difference]\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83340840",
   "metadata": {},
   "source": [
    "Let's take a look at the rate of temperature change per day to see if that makes things clearer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd684d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_slope(x):\n",
    "    slope = np.polyfit(range(len(x)), x, 1)[0]\n",
    "    return slope\n",
    "\n",
    "result = s.rolling(12, min_periods=2).apply(calc_slope) #Use 12 values, which is 3-hours (15-minute data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(result.index, result.values, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcccd98",
   "metadata": {},
   "source": [
    "If we look only at the time around August 13:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3727015",
   "metadata": {},
   "outputs": [],
   "source": [
    "august = np.logical_and(result.index > pd.Timestamp('2023-08-08'), result.index < pd.Timestamp('2023-08-18'))\n",
    "august_data = result[august]\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(august_data.index, august_data.values, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4cb087",
   "metadata": {},
   "source": [
    "It looks like we are missing data for the hottest part of the day! That would certainly explain why we have such a low daily difference. \n",
    "\n",
    "Even though we are collecting data at a very high frequency, we still can miss some! It is always important to check for these things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c55cb7",
   "metadata": {},
   "source": [
    "### Comparing to Rainfall Data\n",
    "\n",
    "As a final step, let's compare some rainfall data for the same location as our temperature sensor, to see how that matches up with our hot/cold days. I will again use the 3-hourly GPM data so that we have a good temporal resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trdam = ee.Geometry.Point([85.14564, 27.92085])\n",
    "\n",
    "hr_rainfall = ee.ImageCollection(\"NASA/GPM_L3/IMERG_V06\").select('precipitationCal').filterDate('2023-05-24', '2024-02-07')\n",
    "hr_rainfall = hr_rainfall.map(mask_) #Remove low values\n",
    "\n",
    "export_timeseries_todrive(hr_rainfall, 'TRDAM_GPM', scale=11132, region=trdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb13b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Time Series/TRDAM_GPM.csv') #Load in our CSV File\n",
    "dates = [pd.Timestamp(x) for x in df.date] #Fix the date to something Python recognizes\n",
    "rain = [float(x.split('=')[1].replace('}','').replace('null','0')) for x in df.val] #Fix the value to something Python recognizes\n",
    "\n",
    "rain = pd.Series(rain, index=dates) #Turn this into an easy to work with time series\n",
    "rs_d = rain.resample('D').sum() #Get the daily mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88911209",
   "metadata": {},
   "source": [
    "Let's make a plot showing the daily temperature range and the daily precipitation sum on the same x-axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a892ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Time Series/TRDam_Temperature_15Min_2023-2024.csv')\n",
    "df['date'] = [pd.Timestamp(x) for x in df.date]\n",
    "temp = pd.Series(df['0'].values, index=df.date)\n",
    "daily_temp_range = temp.resample('D').max() - temp.resample('D').min()\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "ax.plot(daily_temp_range.index, daily_temp_range.values, 'b.')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(rs_d.index, rs_d.values, 'rx')\n",
    "ax2.set_ylim(ymin=0)\n",
    "ax.set_xlabel('Date', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Daily Temperature Range', fontsize=16, fontweight='bold')\n",
    "ax2.set_ylabel('Daily Precipitation Sum', fontsize=16, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c50982",
   "metadata": {},
   "source": [
    "## Further Information\n",
    "\n",
    "We hope that this has helped point out some of the advantages and difficulties of working with high-frequency data! If you want more resources about working with this kind of data, the _pandas_ library is very helpful for doing time-series analysis: [https://pandas.pydata.org/](https://pandas.pydata.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
